{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text, Web, & Media Analytics Assignment 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: ORDER ME PLEASE 🙇‍♂️\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import regex as re\n",
    "import string\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class for Bag-of-Word representation\n",
    "class bow_document:\n",
    "    def __init__(self, item_id: str):\n",
    "        # Type check to ensure object is initialised correctly\n",
    "        if not isinstance(item_id, str):\n",
    "            raise TypeError(\"item_id: value must be a string.\")\n",
    "            # Technically could work with str or int indexing (for key in collection),\n",
    "            # using *only* str ensures no double-up of pointers\n",
    "            # (e.g. item_id '1' vs item_id 1)\n",
    "\n",
    "        self.doc_id = item_id  # assigning doc_id from 'item_id'\n",
    "        self.terms = {}  # dictionary for terms and their frequencies\n",
    "        self._doc_len = 0  # document length, private attribute\n",
    "\n",
    "    def add_term(self, term: str):\n",
    "        \"\"\"Add a term to the document or update its frequency if it already exists.\"\"\"\n",
    "        \n",
    "        # Type check to ensure term is a str\n",
    "        if not isinstance(term, str):\n",
    "            raise TypeError(\"term: value must be a string.\")\n",
    "        \n",
    "        self.doc_len += 1  # extend doc_len\n",
    "\n",
    "        if term in self.terms:\n",
    "            self.terms[term] += 1  # add frequency if the term exists\n",
    "        else:\n",
    "            self.terms[term] = 1  # if it doesn't exist, add it (setting frequency to 1)\n",
    "        \n",
    "    def get_doc_id(self) -> str:\n",
    "        \"\"\"Return the document ID.\"\"\"\n",
    "        return self.doc_id\n",
    "    \n",
    "    def get_term_list(self, sorted_by_freq: bool = None) -> dict:\n",
    "        \"\"\"\n",
    "        Return a list of terms occurring in the document, optionally sorted by their frequency.\n",
    "        If sorted_by_freq is True, the terms are returned sorted by their frequency in descending order.\n",
    "        If sorted_by_freq is False or None (default), the terms are returned in arbitrary order.\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check to ensure sorted_by_freq is either None or a boolean\n",
    "        if not isinstance(sorted_by_freq, (bool, type(None))):\n",
    "            raise TypeError(\"sorted_by_freq: must be a boolean or None.\")\n",
    "\n",
    "        if sorted_by_freq:\n",
    "            # If sorted_by_freq is True\n",
    "            sorted_terms = sorted(self.terms.items(), key=lambda word: word[1], reverse=sorted_by_freq)  # generate a sorted list of terms by frequency\n",
    "            return {term: freq for term, freq in sorted_terms}  # return key:value pairs based on sorted terms\n",
    "        else:\n",
    "            # If sorted_by_freq is False or None, return the terms as is (i.e., unsorted and as they are added in)\n",
    "            return self.terms\n",
    "        \n",
    "    def get_bag_of_words(self, sorted_by_freq: bool = None) -> str:\n",
    "        \"\"\"Return full bag-of-words representation for bow_document object, including; doc_id, term_count, doc_len, and terms.\"\"\"\n",
    "        \n",
    "        # Type check to ensure sorted_by_freq is either None or a boolean\n",
    "        if not isinstance(sorted_by_freq, (bool, type(None))):\n",
    "            raise TypeError(\"sorted_by_freq: must be a boolean or None.\")\n",
    "\n",
    "        # Defining formatted string for bag-of-word representation\n",
    "        bag_of_words = f\"\"\"doc_id='{self.doc_id}',term_count={len(self.get_term_list())},doc_len={self.doc_len},terms={self.get_term_list(sorted_by_freq)}\"\"\"\n",
    "\n",
    "        return bag_of_words  # return BOW representation; this kind of data can be stored and \"unpacked\" easily\n",
    "    \n",
    "    @property  # accessor (get) method for doc_len\n",
    "    def doc_len(self) -> int:\n",
    "        \"\"\"The doc_len property getter method.\"\"\"\n",
    "        return self._doc_len\n",
    "\n",
    "    @doc_len.setter  # mutator (setter) method for doc_len\n",
    "    def doc_len(self, value: int):\n",
    "        \"\"\"The doc_len property setter method.\"\"\"\n",
    "        if not isinstance(value, int):\n",
    "            raise TypeError(\"doc_len: must be an int.\")\n",
    "        if value < 0:\n",
    "            raise ValueError(\"doc_len: must not be negative.\")\n",
    "        \n",
    "        self._doc_len = value\n",
    "\n",
    "# Define the class for collection of bow_document objects\n",
    "class bow_document_collection:\n",
    "    def __init__(self):\n",
    "        self.docs = {}  # initialise dictionary to hold collection (dict) of doc_id:bow_document\n",
    "\n",
    "        self.term_doc_count = {}  # initialise dictionary to track the number of documents each term appears in\n",
    "\n",
    "    # Method to add a doc (bow_document object)\n",
    "    def add_doc(self, doc: bow_document):\n",
    "        \"\"\"Add bow_document object to the collection, using doc_id as the key, and update the inverted index.\"\"\"\n",
    "\n",
    "        # Type check to ensure doc is a bow_document object\n",
    "        if not isinstance(doc, bow_document):\n",
    "            raise TypeError(\"doc: must be an instance of bow_document.\")\n",
    "        \n",
    "        # Add to the docs dict; key as doc_id and value as bow_document object (doc_id:bow_document)\n",
    "        self.docs[doc.get_doc_id()] = doc\n",
    "\n",
    "        # Update term document count for each term\n",
    "        for term in doc.terms:\n",
    "            if term in self.term_doc_count:\n",
    "                self.term_doc_count[term] += 1  # add 1 if the term exists in the corpus dictionary\n",
    "            else:\n",
    "                self.term_doc_count[term] = 1  # if it does not exist in the corpus dictionary, initialise by setting to 1\n",
    "    \n",
    "    def get_collection_ids(self) -> str:\n",
    "        \"\"\"Return list of document IDs present in the collection.\"\"\"\n",
    "\n",
    "        # Type check to ensure doc_id is a string\n",
    "        if not len(self.docs) > 0:\n",
    "            raise AttributeError(\"bow_document_collection object is empty, no IDs to return.\")  # Corrected to match the check\n",
    "        \n",
    "        doc_ids_str = \"'\" + \"', '\".join(self.docs.keys()) + \"'\"  # create a string that lists doc_ids\n",
    "\n",
    "        collection_ids = f\"bow_document_collection(doc_ids: {doc_ids_str})\"  # format the return variable\n",
    "\n",
    "        return collection_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_parser(stop_word_path: str) -> list:\n",
    "    \"\"\"Parse defined list of stop words (assumes txt file with words delimited with ',').\"\"\"\n",
    "\n",
    "    # Type check to ensure stop_word_path is a str\n",
    "    if not isinstance(stop_word_path, str):\n",
    "        raise TypeError(\"stop_word_path: value must be a str.\")\n",
    "    \n",
    "    # NOTE: need attribute check the path exists\n",
    "\n",
    "    # Open file in read mode\n",
    "    with open(stop_word_path, 'r') as file:\n",
    "        stop_words = file.read()  # read text in given file into stop_words\n",
    "\n",
    "    # We know what the format is ahead of time, so not a lot of processing needed;\n",
    "    # i.e., assumes we don't need to make something more robust and that we're using the same txt\n",
    "    stop_words = stop_words.lower().split(\",\")  # tokenize stop_words; delimited with ','\n",
    "    stop_words = list(set(stop_words))  # reduce stop_words to uniques\n",
    "    \n",
    "    return stop_words  # return stop_words as a list object\n",
    "\n",
    "def tokenization(words: str) -> list:\n",
    "    \"\"\"Tokenize input text by removing line breaks, numbers, punctuation, normalizing whitespace, stripping leading/trailing spaces, and splitting into lowercased words.\"\"\"\n",
    "\n",
    "    # Type check to ensure words is a str\n",
    "    if not isinstance(words, str):\n",
    "        raise TypeError(\"words: value must be a str.\")\n",
    "\n",
    "    words = words.replace(\"\\n\", \"\")  # don't want line breaks to contribute\n",
    "    words = re.sub(r'\\d', '', words)  # not interested in numbers for this particular task, remove\n",
    "    words = re.sub(f'[{re.escape(string.punctuation)}]', ' ', words)  # not interested in punctuation, remove\n",
    "    words = re.sub(r'\\s+|\\t+|\\v+|\\n+|\\r+|\\f+', ' ', words).strip()  # standardise the whitespaces, remove leading/trailing whitespace\n",
    "    words = words.lower()  # standardise words as lower\n",
    "    words = words.split()  # tokenize, deftault split on space\n",
    "\n",
    "    # Filter out small words; can be important in some queries, usually in combinations, opting not to handle for simplicity.\n",
    "    # For example, with no discrete management of apostrophes (indicating contractions or posession) aside from replacement \n",
    "    # of punctuation with a single space, we will get the following: \"Amelia's\" → [\"Amelia\", \"s\"] → [\"Amelia\"].\n",
    "    # Unless they are actual words (e.g., \"I\" versus \"s\" or \"t\"), they won't be removed in stopping process.\n",
    "    words = [word for word in words if len(word) >= 3]\n",
    "\n",
    "    return words  # return list object of string words\n",
    "\n",
    "def xml_parser(stop_words: list, xml_path: str) -> bow_document:\n",
    "    \"\"\"Parse a single XML file, process text, and return an bow_document object with term frequencies.\"\"\"\n",
    "    \n",
    "    # Type check to ensure stop_words is a list of str\n",
    "    if not isinstance(stop_words, list) or not all(isinstance(word, str) for word in stop_words):\n",
    "        raise TypeError(\"stop_words: must be a list of strings.\")\n",
    "    \n",
    "    # Type check to ensure xml_path is a str\n",
    "    if not isinstance(xml_path, str):\n",
    "        raise TypeError(\"xml_path: value must be a str.\")\n",
    "    \n",
    "    # Check if provided xml_path is a valid xml file, raise AttributeError if it is not\n",
    "    if not ((os.path.isfile(xml_path)) and (xml_path.lower().endswith(\".xml\"))):\n",
    "        raise AttributeError(f\"\"\"xml_path: '{xml_path}' is not a valid xml file.\"\"\")\n",
    "        # NOTE: check is included here for targeting single xml (wheras parse_rcv1v2() executes this check in loop)\n",
    "\n",
    "    # DOCUMENT PARSING - recognition of the content and structure of text documents\n",
    "    # Open file in read mode\n",
    "    with open(xml_path, 'r') as file:\n",
    "        xml = file.read()  # read xml in given file\n",
    "\n",
    "    text = re.search(r'<text>\\s*((?:<p>.*?</p>\\s*)+)</text>', xml, re.DOTALL)  # find all text within the <text> tag\n",
    "\n",
    "    # If no text found, raise attribute error; else return match group 1\n",
    "    if not text:\n",
    "        raise AttributeError(fr\"\"\"xml_path: '{xml_path}' did not contain any text, see text tag (expect match at '<text>\\s*((?:<p>.*?</p>\\s*)+)</text>' with re.DOTALL).\"\"\") \n",
    "    else:\n",
    "        text = text.group(1)\n",
    "\n",
    "    # Replace HTML entities with their corresponding characters\n",
    "    html_entities = {\"&lt;\": \"<\", \"&gt;\": \">\", \"&amp;\": \"&\", \"&quot;\": \"\\\"\", \"&apos;\": \"'\", \"&nbsp;\": \" \" }\n",
    "    for entity, char in html_entities.items():\n",
    "        text = text.replace(entity, char)\n",
    "    \n",
    "    text = re.sub(r'<.*?>', ' ', text).strip()  # remove any XML tags (p tags in our case)\n",
    "    \n",
    "    # TOKENIZING - forming words from sequence of characters; critically, generating a list of tokens\n",
    "    words = tokenization(text)\n",
    "    \n",
    "    # POSTING - a collection of arbitrary data (including a pointer)\n",
    "    item_id = re.search(r'<newsitem itemid=\"(\\d+)\"', xml)  # POINTER - a unique identifier of a document (item_id attribute from newsitem element in this case)\n",
    "\n",
    "    if not item_id:\n",
    "        # If no item_id found, raise attribute error\n",
    "        raise AttributeError(f\"\"\"xml_path: '{xml_path}' did not contain pointer, see item_id attribute in newsitem tag (expect match at '<newsitem itemid=\"(\\\\d+)\"').\"\"\") \n",
    "    else:\n",
    "        item_id = item_id.group(1)  # otherwise, take group 1 of regex (just the \\d+ match component)\n",
    "        \n",
    "    document = bow_document(item_id)  # initialise bow_document object with the pointer (item_id)\n",
    "\n",
    "    # STOPPING - removing stop (function) words from the text being analysed; have little meaning on their own\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # STEMMING - reducing words to their word stem, base or root form (remove morphological variations)\n",
    "    stemmer = nltk.stem.PorterStemmer()  # Porter Stemmer: efficient for information retrieval and text processing tasks – can often create non-words in favour of faster speeds\n",
    "    words = [stemmer.stem(word) for word in words] \n",
    "    \n",
    "    # Iterate over each stemmed word\n",
    "    for stemmed_word in words:\n",
    "        document.add_term(stemmed_word)  # use method add_term to update the bow_document object (our arbitrary data)          \n",
    "\n",
    "    return document  # return the bow_document object\n",
    "\n",
    "def parse_rcv1v2(stop_words: list, input_path: str) -> bow_document_collection:\n",
    "    \"\"\"Parse XML documents in a directory, filter stop words, and return a collection of bow_document objects.\"\"\"\n",
    "    \n",
    "    # Type check to ensure stop_words is a list of str\n",
    "    if not isinstance(stop_words, list) or not all(isinstance(word, str) for word in stop_words):\n",
    "        raise TypeError(\"stop_words: must be a list of strings.\")\n",
    "    \n",
    "    # Type check to ensure input_path is a str\n",
    "    if not isinstance(input_path, str):\n",
    "        raise TypeError(\"input_path: value must be a str.\")\n",
    "    \n",
    "    # NOTE: need to do attribute check to see if input_path exists\n",
    "\n",
    "    collection = bow_document_collection()  # initialise bow_document_collection object (collection of bow_document objects)\n",
    "    \n",
    "    # Iterate through files in directory\n",
    "    for xml_file in os.listdir(input_path):\n",
    "        xml_path = os.path.join(input_path, xml_file)  # build path to files\n",
    "        if ((os.path.isfile(xml_path)) and (xml_path.lower().endswith(\".xml\"))):\n",
    "            doc = xml_parser(stop_words, xml_path)  # parse xml with xml_parser function\n",
    "            collection.add_doc(doc)  # use method add_doc to update the bow_document_collection object\n",
    "\n",
    "    # If no xmls parsed (i.e., collection length is 0), raise attribute error\n",
    "    if len(collection.docs) == 0:\n",
    "        raise AttributeError(f\"\"\"input_path: '{input_path}' did not contain any valid xml files.\"\"\")\n",
    "\n",
    "    return collection  # return the bow_document_collection object\n",
    "\n",
    "def parse_query(query: str, stop_words: list) -> dict:\n",
    "    \"\"\"Tokenize an input query, remove stop words, and return a dictionary of remaining word frequencies.\"\"\"\n",
    "\n",
    "    # Type check to ensure stop_words is a list of str\n",
    "    if not isinstance(stop_words, list) or not all(isinstance(word, str) for word in stop_words):\n",
    "        raise TypeError(\"stop_words: must be a list of strings.\")\n",
    "    \n",
    "    # Type check to ensure query is a str\n",
    "    if not isinstance(query, str):\n",
    "        raise TypeError(\"query: value must be a string.\")\n",
    "    \n",
    "    # TOKENIZING - forming words from sequence of characters; critically, generating a list of tokens\n",
    "    words = tokenization(query)\n",
    "    \n",
    "    # STOPPING - removing stop (function) words from the text being analysed; have little meaning on their own\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # STEMMING - reducing words to their word stem, base or root form (remove morphological variations)\n",
    "    stemmer = nltk.stem.PorterStemmer()  # Porter Stemmer: efficient for information retrieval and text processing tasks – though can often create non-words in favour of faster speeds\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Constrcut term:frequency dictionary by counting instances of each word (more efficient than for loop + if/else)\n",
    "    query_term_frequency = {stemmed_word: words.count(stemmed_word) for stemmed_word in set(words)}\n",
    "\n",
    "    return query_term_frequency  # return the dictionary containing word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_queries(query_set: str) -> pd.DataFrame:\n",
    "    \n",
    "    # Type check to ensure the query_set is a string\n",
    "    if not isinstance(query_set, str):\n",
    "        raise TypeError(\"query_set: value must be a string.\")\n",
    "    \n",
    "    # Check to see if the query_set exists\n",
    "    if not os.path.exists(query_set):\n",
    "        raise AttributeError(\"query_set: file does not exist.\")\n",
    "        \n",
    "    with open(query_set, 'r') as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    # Define regex pattern to split queries\n",
    "    query_pattern = re.compile(r'<Query>(.*?)</Query>', re.DOTALL)\n",
    "    queries = query_pattern.findall(data)\n",
    "    \n",
    "    # Initialize lists for storing parsed data\n",
    "    nums, titles, descriptions, narratives = [], [], [], []\n",
    "    \n",
    "    # Define regex patterns to extract individual fields\n",
    "    num_pattern = re.compile(r'<num>\\s*Number:\\s*R(\\w+)', re.MULTILINE)\n",
    "    title_pattern = re.compile(r'<title>([\\w\\s,.-]*)', re.MULTILINE)\n",
    "    desc_pattern = re.compile(r'<desc>\\s*Description:\\s*(.*?)\\n\\n', re.DOTALL)\n",
    "    narr_pattern = re.compile(r'<narr>\\s*Narrative:\\s*(.*?)\\n\\n', re.DOTALL)\n",
    "    \n",
    "    for query in queries:\n",
    "        # Extract data using regex patterns\n",
    "        num_match = num_pattern.search(query)\n",
    "        title_match = title_pattern.search(query)\n",
    "        desc_match = desc_pattern.search(query)\n",
    "        narr_match = narr_pattern.search(query)\n",
    "        \n",
    "        nums.append(num_match.group(1) if num_match else pd.NA)\n",
    "        titles.append(title_match.group(1).strip() if title_match else pd.NA)\n",
    "        descriptions.append(desc_match.group(1).strip() if desc_match else pd.NA)\n",
    "        narratives.append(narr_match.group(1).strip() if narr_match else pd.NA)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    query_frame = pd.DataFrame({\n",
    "        'number': nums,\n",
    "        'title': titles,\n",
    "        'description': descriptions,\n",
    "        'narrative': narratives\n",
    "    })\n",
    "\n",
    "    return query_frame\n",
    "\n",
    "def evaluation_loader(evaluation_path: str) -> dict:\n",
    "    # Type check to ensure the evaluation_path is a string\n",
    "    if not isinstance(evaluation_path, str):\n",
    "        raise TypeError(\"evaluation_path: value must be a string.\")\n",
    "    \n",
    "    # Check to see if the evaluation_path exists\n",
    "    if not os.path.exists(evaluation_path):\n",
    "        raise AttributeError(\"evaluation_path: directory does not exist.\")\n",
    "\n",
    "    # Load document relevance from evaluation files\n",
    "    relevance_data = []\n",
    "    for filename in os.listdir(evaluation_path):\n",
    "        if filename.startswith(\"Dataset\") and filename.endswith(\".txt\"):\n",
    "            path = os.path.join(evaluation_path, filename)\n",
    "            query_relevance = pd.read_csv(path, sep=' ', names=['number', 'docID', 'relevance'], dtype={'number': str, 'docID': str, 'relevance': int})\n",
    "            query_relevance['number'] = query_relevance['number'].str[1:]  # Remove the 'R' prefix\n",
    "            relevance_data.append(query_relevance)\n",
    "\n",
    "    # Check if relevency judgements were found\n",
    "    if not relevance_data:\n",
    "        raise FileNotFoundError(r\"evaluation_path: no r'Dataset\\d+.txt' files were found in the directory.\")\n",
    "\n",
    "    # Concatenate all dataframes into one\n",
    "    relevance_frame = pd.concat(relevance_data, ignore_index=True)\n",
    "    \n",
    "    # Create lists of relevant and non-relevant documents\n",
    "    relevance_frame['docID'] = relevance_frame['docID'].astype(str)\n",
    "    grouped = relevance_frame.groupby(['number', 'relevance'])\n",
    "    relevance_lists = grouped['docID'].agg(list).unstack(fill_value=[]).reset_index()\n",
    "    relevance_lists.columns = ['number', 'non_relevant_docs', 'relevant_docs']\n",
    "    relevance_lists = relevance_lists[['number', 'relevant_docs', 'non_relevant_docs']]\n",
    "    relevance_lists = relevance_lists.set_index('number').apply(lambda row: row.to_dict(), axis=1).to_dict()\n",
    "\n",
    "    return relevance_lists\n",
    "\n",
    "def write_scores_to_file(scores: dict, filename: str):\n",
    "    \"\"\"\n",
    "    Write the scores dictionary to a .dat file.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(scores, dict):\n",
    "        raise TypeError(\"scores: value must be a dictionary.\")\n",
    "    \n",
    "    if not all((isinstance(doc_id, str)) and (isinstance(score, (int, float))) for doc_id, score in scores.items()):\n",
    "        raise ValueError(\"scores: dictionary must consist of string keys (for documents) and int/float values (for document scores).\")\n",
    "\n",
    "    if not isinstance(filename, str):\n",
    "        raise TypeError(\"filename: value must be a string.\")\n",
    "    \n",
    "    # Combine the directory and filename to form the full path\n",
    "    directory = 'RankingOutputs'\n",
    "    filepath = os.path.join(directory, filename)\n",
    "\n",
    "    # Check if the directory exists, and create it if it doesn't\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    with open(filepath, 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')  # Using tab delimiter for .dat format\n",
    "        for doc_id, score in scores.items():\n",
    "            writer.writerow([doc_id, score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** Design a BM25-based IR model (**BM25**) that ranks documents in each data collection using the corresponding topic (query) for all 50 data collections.\n",
    "\n",
    "\n",
    "**Inputs:** 50 long queries (topics) in *the50Queries.txt* and the corresponding 50 data collections (*Data_C101, Data_C102, …, Data_C150*).\n",
    "\n",
    "\n",
    "**Output:** 50 ranked document files (e.g., for Query *R107*, the output file name is “BM25_R107Ranking.dat”) for all 50 data collections and save them in the folder “RankingOutputs”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each long query (topic) $Q$, you need to use the following equation to calculate a score for each document $D$ in the corresponding data collection (dataset):\n",
    "\n",
    "$\\sum_{i \\in Q} \\log_{10}(\\frac{(r_i + 0.5)/(R-r_i+0.5)}{(n_i-r_i+0.5)/(N-n_i-R+r_i+0.5)})\\cdot\\frac{(k_1+1)f_i}{K+f_i}\\cdot\\frac{(k_2+1)qf_i}{k_2+qf_i}$\n",
    "\n",
    "- $Q$ is the title of the long query, \n",
    "- $k_1 = 1.2$\n",
    "- $k_2=500$\n",
    "- $b = 0.75$\n",
    "- $dl = len(D)$\n",
    "- $avdl$ is the average length of a document in the dataset. \n",
    "- $K = k1\\cdot((1-b) + b\\cdot dl /avdl)$\n",
    "- The ***base of the log function is 10***. \n",
    "\n",
    "Note that *BM25 values can be negative*, and you may need to update the above equation to produce non-negative values but keep the resulting documents in the same rank order.\n",
    "\n",
    "**Formally describe your design for BM25** in an algorithm to **rank documents in each data collection *using corresponding query* (topic) ***for all 50 data collections*****. When you use the BM25 score to rank the documents of each data collection, you also need to **answer what the query feature function and document feature function are**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(collection: bow_document_collection, query: dict) -> dict:\n",
    "    \"\"\"\n",
    "    BM25 ranking function for a collection of documents and a given query.\n",
    "    Generates a score for a given documents term:frequency set.\n",
    "    Incorporates term frequency (TF) and inverse document frequency (IDF) factors. \n",
    "    It accounts for term frequency saturation as well as document length bias.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Type check to ensure coll is a bow_document_collection\n",
    "    if not isinstance(collection, bow_document_collection):\n",
    "        raise TypeError(\"collection: must be a bow_document_collection object.\")\n",
    "    \n",
    "    # If no collection contains no documents, raise attribute error\n",
    "    if len(collection.docs) == 0:\n",
    "        raise AttributeError(\"bow_document_collectionection: object contains no documents (Rcv1Doc objects).\")\n",
    "    \n",
    "    # Type check to ensure query is a dict\n",
    "    if not isinstance(query, dict):\n",
    "        raise TypeError(\"query: must be a dict object.\")\n",
    "    \n",
    "    # Setting parameters\n",
    "    k_1 = 1.2  # Controls non-linear term frequency normalization (saturation)\n",
    "    k_2 = 500  # Controls non-linear term frequency normalization for query terms\n",
    "    b = 0.75  # Controls to what degree document length normalizes tf values\n",
    "\n",
    "    N = len(collection.docs)  # total number of documents in the collection\n",
    "    R = 0  # number of relevant documents for this query; predefined by task\n",
    "    r_i = 0  # number of relevant documents containing query term i; predefined by task\n",
    "\n",
    "    # Calculate the average document length across the entire collection\n",
    "    total_corpus_length = sum(doc.doc_len for doc in collection.docs.values())\n",
    "    mean_doc_len = total_corpus_length / N\n",
    "    \n",
    "    doc_scores = {}  # initialize doc_score dictionary to store calculated scores\n",
    "\n",
    "    # Loop through each term in the query.\n",
    "    for query_term, query_frequency in query.items():\n",
    "        n_i = collection.term_doc_count.get(query_term, 0)  # the number of documents containing term i (0 if not present)\n",
    "\n",
    "        # Calculate the inverse document frequency for the term\n",
    "        idf_component = math.log10(((r_i + 0.5)/(R - r_i + 0.5)) / ((n_i - r_i + 0.5) / (N - n_i - R + r_i + 0.5)))\n",
    "        # idf_component = math.log10((N - n_i + 0.5) / (n_i + 0.5))  # NOTE: simplified, need feedback from Slack\n",
    "\n",
    "        # Component measures the rarity of the term across the entire collection; \n",
    "        # term appearing in fewer documents will have a higher IDF, making it more influential.\n",
    "        # Formula ensures that no division by zero occurs by introducing additive smoothing of 0.5 to the numerator and denominator.\n",
    "\n",
    "        for doc_id, doc in collection.docs.items():\n",
    "            doc_len = doc.doc_len  # document length\n",
    "\n",
    "            K = k_1 * ((1 - b) + b * doc_len / mean_doc_len)  # frequency normaliser\n",
    "            \n",
    "            document_term_frequency = doc.terms.get(query_term, 0)  # query term frequency within the document (0 if not present)\n",
    "            \n",
    "            # Calculate the term frequency normalization for the document term\n",
    "            tf_component = ((k_1 + 1) * document_term_frequency) / (K + document_term_frequency)\n",
    "            # This component adjusts the score based on the frequency of the term in the document.\n",
    "            # The normalisation (denominator) prevents over-emphasis on terms that appear too frequently within a single document.\n",
    "            # `k_1` controls the non-linear term frequency saturation, and `K` adjusts the weight based on document length.\n",
    "\n",
    "            # Calculate the query term frequency normalization\n",
    "            query_component = ((k_2 + 1) * query_frequency) / (k_2 + query_frequency)\n",
    "            # Adjusts the score based on the query term's frequency.\n",
    "            # Denominator prevents over-emphasis on query terms that appear frequently.\n",
    "            \n",
    "            score = idf_component * tf_component * query_component  # determine the score (can be non-negative, clamping used below to adjust)\n",
    "            \n",
    "            if doc_id not in doc_scores:\n",
    "                doc_scores[doc_id] = 0  # initialize doc_score if not present\n",
    "            \n",
    "            doc_scores[doc_id] += max(score, 0)  # update the document's score with the product of the IDF and TF components (clamping non-negatives to 0)\n",
    "    \n",
    "    doc_scores = dict(sorted(doc_scores.items(), key=lambda item: item[1], reverse=True))  # sort the results\n",
    "\n",
    "    # Return the document score\n",
    "    return doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stop_word_parser('common-english-words.txt')\n",
    "\n",
    "query_frame = parse_queries('the50Queries.txt')\n",
    "query_frame['parsed_titles'] = query_frame['title'].apply(lambda row: parse_query(row, stop_words))\n",
    "\n",
    "document_set = {}\n",
    "\n",
    "input_path = 'Data_Collection'\n",
    "for collection_path in os.listdir(input_path):\n",
    "    data_key = collection_path.split('_C', 1)[1]\n",
    "    document_set[data_key] = parse_rcv1v2(stop_words, os.path.join(input_path, collection_path))\n",
    "\n",
    "relevance_lists = evaluation_loader('EvaluationBenchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_specificity(collection: bow_document_collection, query: dict, relevant_docs: list, non_relevant_docs: list, theta_1: float | int, theta_2: float | int) -> dict:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Type check to ensure coll is a bow_document_collection\n",
    "    if not isinstance(collection, bow_document_collection):\n",
    "        raise TypeError(\"collection: must be a bow_document_collection object.\")\n",
    "    \n",
    "    # If no collection contains no documents, raise attribute error\n",
    "    if len(collection.docs) == 0:\n",
    "        raise AttributeError(\"bow_document_collectionection: object contains no documents (Rcv1Doc objects).\")\n",
    "    \n",
    "    # Type check to ensure query is a dict\n",
    "    if not isinstance(query, dict):\n",
    "        raise TypeError(\"query: must be a dict object.\")\n",
    "    \n",
    "    # Type check to ensure relevant_docs & non_relevant_docs are lists\n",
    "    if not isinstance(relevant_docs, list) or not all(isinstance(doc_id, str) for doc_id in relevant_docs):\n",
    "        raise TypeError(\"relevant_docs: must be a list of strings.\")\n",
    "    if not isinstance(non_relevant_docs, list) or not all(isinstance(doc_id, str) for doc_id in non_relevant_docs):\n",
    "        raise TypeError(\"non_relevant_docs: must be a list of strings.\")\n",
    "    \n",
    "    # Training doc check\n",
    "    if not len(relevant_docs) > 0:\n",
    "        raise AttributeError(\"relevant_docs: must specify at least one relevant document.\")\n",
    "    if not len(non_relevant_docs) > 0:\n",
    "        raise AttributeError(\"non_relevant_docs: must specify at least one relevant document.\")\n",
    "    \n",
    "    # Type check to ensure theta_1 & theta_2 are floats\n",
    "    if not isinstance(theta_1, (float, int)):\n",
    "        raise TypeError(\"theta_1: must be a float or int value.\")\n",
    "    if not isinstance(theta_2, (float, int)):\n",
    "        raise TypeError(\"theta_2: must be a float or int value.\")\n",
    "    \n",
    "    # Boundary check\n",
    "    if not theta_2 > theta_1:\n",
    "        raise ValueError(\"theta_2: must be greater than theta_1.\")\n",
    "            \n",
    "    specificity = {}\n",
    "\n",
    "    D = len(relevant_docs)\n",
    "    \n",
    "    # Loop through each term in the query.\n",
    "    for query_term in query.keys():\n",
    "        positive_coverage = 0\n",
    "        negative_coverage = 0\n",
    "        for doc_id, doc in collection.docs.items():\n",
    "            if doc_id in relevant_docs:\n",
    "                positive_coverage += doc.terms.get(query_term, 0)\n",
    "            elif doc_id in non_relevant_docs:\n",
    "                negative_coverage += doc.terms.get(query_term, 0)\n",
    "        \n",
    "        specificity[query_term] = (positive_coverage - negative_coverage) / D\n",
    "\n",
    "    positive_terms = [term for term in specificity if specificity[term] >= theta_2]\n",
    "    general_terms = [term for term in specificity if theta_1 < specificity[term] < theta_2]\n",
    "    negative_terms = [term for term in specificity if specificity[term] <= theta_1]\n",
    "\n",
    "    weighted_terms = {}\n",
    "\n",
    "    for query_term, query_term_frequency in query.items():\n",
    "        if query_term in positive_terms:\n",
    "            weighted_terms[query_term] = query_term_frequency + query_term_frequency * specificity[query_term]\n",
    "        elif query_term in general_terms:\n",
    "            weighted_terms[query_term] = query_term_frequency\n",
    "        elif query_term in negative_terms:\n",
    "            weighted_terms[query_term] = query_term_frequency - abs(query_term_frequency * specificity[query_term])\n",
    "\n",
    "    return weighted_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term_specificity(collection: bow_document_collection, query: dict, relevant_docs: list, non_relevant_docs: list)\n",
    "query_frame['weighted_terms'] =\\\n",
    "    query_frame.apply(lambda row: \n",
    "        term_specificity(document_set[row['number']], row['parsed_titles'], \n",
    "                         relevance_lists[row['number']]['relevant_docs'], relevance_lists[row['number']]['non_relevant_docs'], 0.0, 0.5), \n",
    "        axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>narrative</th>\n",
       "      <th>parsed_titles</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>weighted_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Economic espionage</td>\n",
       "      <td>What is being done to counter economic espiona...</td>\n",
       "      <td>Documents which identify economic espionage ca...</td>\n",
       "      <td>{'espionag': 1, 'econom': 1}</td>\n",
       "      <td>{'espionag': -0.2857142857142857, 'econom': 0....</td>\n",
       "      <td>{'espionag': 0.7142857142857143, 'econom': 1.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Convicts, repeat offenders</td>\n",
       "      <td>Search for information pertaining to crimes co...</td>\n",
       "      <td>Relevant documents are those which cite actual...</td>\n",
       "      <td>{'offend': 1, 'repeat': 1, 'convict': 1}</td>\n",
       "      <td>{'offend': 0.2222222222222222, 'repeat': 0.103...</td>\n",
       "      <td>{'offend': 1, 'repeat': 1, 'convict': 2.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Ferry Boat sinkings</td>\n",
       "      <td>Documents will report on any sinkings of Ferry...</td>\n",
       "      <td>Documents that identify any instances where a ...</td>\n",
       "      <td>{'boat': 1, 'ferri': 1, 'sink': 1}</td>\n",
       "      <td>{'boat': -3.2857142857142856, 'ferri': -2.8571...</td>\n",
       "      <td>{'boat': -2.2857142857142856, 'ferri': -1.8571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Rescue of kidnapped children</td>\n",
       "      <td>Identify a kidnapping of a child or children w...</td>\n",
       "      <td>Documents discussing abducted or kidnapped chi...</td>\n",
       "      <td>{'kidnap': 1, 'rescu': 1, 'children': 1}</td>\n",
       "      <td>{'kidnap': 1.425, 'rescu': 1.0916666666666666,...</td>\n",
       "      <td>{'kidnap': 2.425, 'rescu': 2.091666666666667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Sport Utility Vehicles U.S.</td>\n",
       "      <td>Find documents that will illustrate the phenom...</td>\n",
       "      <td>Documents that discuss the growth in ownership...</td>\n",
       "      <td>{'util': 1, 'sport': 1, 'vehicl': 1}</td>\n",
       "      <td>{'util': 0.8125, 'sport': 2.25, 'vehicl': 3.9375}</td>\n",
       "      <td>{'util': 1.8125, 'sport': 3.25, 'vehicl': 4.9375}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>Government supported school vouchers</td>\n",
       "      <td>Research documents on the pros/cons of governm...</td>\n",
       "      <td>Documents containing statements by elected off...</td>\n",
       "      <td>{'support': 1, 'govern': 1, 'school': 1, 'vouc...</td>\n",
       "      <td>{'support': -1.25, 'govern': -5.5, 'school': -...</td>\n",
       "      <td>{'support': -0.25, 'govern': -4.5, 'school': -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Tourism Great Britain</td>\n",
       "      <td>Retrieve documents pertaining to tourism into ...</td>\n",
       "      <td>Documents about Scotland, Wales and only North...</td>\n",
       "      <td>{'great': 1, 'britain': 1, 'tourism': 1}</td>\n",
       "      <td>{'great': -0.3333333333333333, 'britain': 0.66...</td>\n",
       "      <td>{'great': 0.6666666666666667, 'britain': 1.666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>Harmful weight-loss drugs</td>\n",
       "      <td>Identify medicines used for obesity or weight-...</td>\n",
       "      <td>Relevant documents will show specific, harmful...</td>\n",
       "      <td>{'loss': 1, 'harm': 1, 'weight': 1, 'drug': 1}</td>\n",
       "      <td>{'loss': -12.0, 'harm': -0.6666666666666666, '...</td>\n",
       "      <td>{'loss': -11.0, 'harm': 0.33333333333333337, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>Child custody cases</td>\n",
       "      <td>Research reports on child custody cases.</td>\n",
       "      <td>Relevant documents concentrate on custody case...</td>\n",
       "      <td>{'case': 1, 'child': 1, 'custodi': 1}</td>\n",
       "      <td>{'case': 1.55, 'child': -0.55, 'custodi': 1.5}</td>\n",
       "      <td>{'case': 2.55, 'child': 0.44999999999999996, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>Terrorism Middle East tourism</td>\n",
       "      <td>What effect has Middle East terrorism had on t...</td>\n",
       "      <td>Relevant documents directly correlate terroris...</td>\n",
       "      <td>{'terror': 1, 'middl': 1, 'east': 1, 'tourism'...</td>\n",
       "      <td>{'terror': -1.6, 'middl': -18.8, 'east': -37.0...</td>\n",
       "      <td>{'terror': -0.6000000000000001, 'middl': -17.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "      <td>Telemarketing practices U.S.</td>\n",
       "      <td>Find documents which reflect telemarketing pra...</td>\n",
       "      <td>Telemarketing practices found to be abusive, i...</td>\n",
       "      <td>{'telemarket': 1, 'practic': 1}</td>\n",
       "      <td>{'telemarket': -2.3333333333333335, 'practic':...</td>\n",
       "      <td>{'telemarket': -1.3333333333333335, 'practic':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112</td>\n",
       "      <td>School bus accidents</td>\n",
       "      <td>Identify any documents noting school bus accid...</td>\n",
       "      <td>Relevant documents will identify any instances...</td>\n",
       "      <td>{'accid': 1, 'school': 1, 'bu': 1}</td>\n",
       "      <td>{'accid': -4.5, 'school': -0.5, 'bu': -5.16666...</td>\n",
       "      <td>{'accid': -3.5, 'school': 0.5, 'bu': -4.166666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>Ford foreign ventures</td>\n",
       "      <td>Track joint ventures, partnerships and coopera...</td>\n",
       "      <td>Current, intact ventures are the only ones rel...</td>\n",
       "      <td>{'ford': 1, 'foreign': 1, 'ventur': 1}</td>\n",
       "      <td>{'ford': -15.416666666666666, 'foreign': -0.41...</td>\n",
       "      <td>{'ford': -14.416666666666666, 'foreign': 0.583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114</td>\n",
       "      <td>Effects of global warming</td>\n",
       "      <td>Evidence of effects of global warming or the g...</td>\n",
       "      <td>Only articles that describe actual changes due...</td>\n",
       "      <td>{'effect': 1, 'warm': 1, 'global': 1}</td>\n",
       "      <td>{'effect': -0.2, 'warm': -1.2, 'global': -2.4}</td>\n",
       "      <td>{'effect': 0.8, 'warm': -0.19999999999999996, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>115</td>\n",
       "      <td>Indian casino laws</td>\n",
       "      <td>Research the state laws regarding the construc...</td>\n",
       "      <td>Documents that show laws and ballot initiative...</td>\n",
       "      <td>{'indian': 1, 'casino': 1, 'law': 1}</td>\n",
       "      <td>{'indian': 0.3333333333333333, 'casino': -35.6...</td>\n",
       "      <td>{'indian': 1, 'casino': -34.666666666666664, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>116</td>\n",
       "      <td>Archaeology discoveries</td>\n",
       "      <td>Find current documents on new archaeological d...</td>\n",
       "      <td>Documents interpreting former discoveries shou...</td>\n",
       "      <td>{'archaeolog': 1, 'discoveri': 1}</td>\n",
       "      <td>{'archaeolog': -0.375, 'discoveri': -4.125}</td>\n",
       "      <td>{'archaeolog': 0.625, 'discoveri': -3.125}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>117</td>\n",
       "      <td>Organ transplants in the UK</td>\n",
       "      <td>Research reports on organ transplantation in t...</td>\n",
       "      <td>Reports on actual organ transplant cases are r...</td>\n",
       "      <td>{'organ': 1, 'transplant': 1}</td>\n",
       "      <td>{'organ': -4.666666666666667, 'transplant': -1...</td>\n",
       "      <td>{'organ': -3.666666666666667, 'transplant': -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>118</td>\n",
       "      <td>Progress in treatment of schizophrenia</td>\n",
       "      <td>Provide documents reflecting any progress in m...</td>\n",
       "      <td>Documents providing the names of drugs used as...</td>\n",
       "      <td>{'treatment': 1, 'schizophrenia': 1, 'progress...</td>\n",
       "      <td>{'treatment': -8.666666666666666, 'schizophren...</td>\n",
       "      <td>{'treatment': -7.666666666666666, 'schizophren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>119</td>\n",
       "      <td>U.S. gas prices</td>\n",
       "      <td>Find documents discussing possible reasons for...</td>\n",
       "      <td>Documents that provide reasons why U.S. gasoli...</td>\n",
       "      <td>{'price': 1, 'ga': 1}</td>\n",
       "      <td>{'price': -65.75, 'ga': -3.5}</td>\n",
       "      <td>{'price': -64.75, 'ga': -2.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>120</td>\n",
       "      <td>Deaths mining accidents</td>\n",
       "      <td>Identify any documents mentioning deaths in mi...</td>\n",
       "      <td>Documents listing statistics on number of mini...</td>\n",
       "      <td>{'mine': 1, 'accid': 1, 'death': 1}</td>\n",
       "      <td>{'mine': -30.11111111111111, 'accid': -0.22222...</td>\n",
       "      <td>{'mine': -29.11111111111111, 'accid': 0.777777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>121</td>\n",
       "      <td>China Pakistan nuclear missile</td>\n",
       "      <td>Search for evidence of whether or not China is...</td>\n",
       "      <td>Documents which contain information confirming...</td>\n",
       "      <td>{'nuclear': 1, 'missil': 1, 'china': 1, 'pakis...</td>\n",
       "      <td>{'nuclear': -13.142857142857142, 'missil': -2....</td>\n",
       "      <td>{'nuclear': -12.142857142857142, 'missil': -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>122</td>\n",
       "      <td>Symptoms Parkinson</td>\n",
       "      <td>Find early symptoms of diagnosing Parkinson's ...</td>\n",
       "      <td>Documents discussing people with Parkinsons wi...</td>\n",
       "      <td>{'symptom': 1, 'parkinson': 1}</td>\n",
       "      <td>{'symptom': -0.5333333333333333, 'parkinson': ...</td>\n",
       "      <td>{'symptom': 0.4666666666666667, 'parkinson': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>123</td>\n",
       "      <td>Newspaper circulation decline</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Documents which cite both circulation decline ...</td>\n",
       "      <td>{'newspap': 1, 'declin': 1, 'circul': 1}</td>\n",
       "      <td>{'newspap': -48.666666666666664, 'declin': -4....</td>\n",
       "      <td>{'newspap': -47.666666666666664, 'declin': -3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>124</td>\n",
       "      <td>Aborigine health</td>\n",
       "      <td>Research reports on the health of aborigine pe...</td>\n",
       "      <td>Relevant documents will address current attemp...</td>\n",
       "      <td>{'health': 1, 'aborigin': 1}</td>\n",
       "      <td>{'health': -4.166666666666667, 'aborigin': -8....</td>\n",
       "      <td>{'health': -3.166666666666667, 'aborigin': -7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>125</td>\n",
       "      <td>Scottish Independence</td>\n",
       "      <td>The Scottish people have been pushing for inde...</td>\n",
       "      <td>Documents that only discuss creation of a Scot...</td>\n",
       "      <td>{'scottish': 1, 'independ': 1}</td>\n",
       "      <td>{'scottish': 0.5, 'independ': 1.75}</td>\n",
       "      <td>{'scottish': 1.5, 'independ': 2.75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>126</td>\n",
       "      <td>Nuclear plants U.S.</td>\n",
       "      <td>Find the location and status of United States ...</td>\n",
       "      <td>Documents giving a specific location of a nucl...</td>\n",
       "      <td>{'plant': 1, 'nuclear': 1}</td>\n",
       "      <td>{'plant': -0.7368421052631579, 'nuclear': -0.5...</td>\n",
       "      <td>{'plant': 0.26315789473684215, 'nuclear': 0.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>127</td>\n",
       "      <td>U.S. automobile seat belt</td>\n",
       "      <td>Find documents concerning the use of automobil...</td>\n",
       "      <td>Relevant documents show the use of seat belts ...</td>\n",
       "      <td>{'belt': 1, 'automobil': 1, 'seat': 1}</td>\n",
       "      <td>{'belt': -0.2, 'automobil': 0.2, 'seat': -4.8}</td>\n",
       "      <td>{'belt': 0.8, 'automobil': 1, 'seat': -3.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>128</td>\n",
       "      <td>Child labor laws</td>\n",
       "      <td>Research documents covering the current state ...</td>\n",
       "      <td>Relevant documents discuss the creation of law...</td>\n",
       "      <td>{'labor': 1, 'child': 1, 'law': 1}</td>\n",
       "      <td>{'labor': -11.75, 'child': -41.0, 'law': -19.25}</td>\n",
       "      <td>{'labor': -10.75, 'child': -40.0, 'law': -18.25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>129</td>\n",
       "      <td>Problems illegal aliens U.S.</td>\n",
       "      <td>Find documents referencing problems resulting ...</td>\n",
       "      <td>Documents that mention illegal alien activity ...</td>\n",
       "      <td>{'alien': 1, 'problem': 1, 'illeg': 1}</td>\n",
       "      <td>{'alien': 1.0588235294117647, 'problem': -0.41...</td>\n",
       "      <td>{'alien': 2.0588235294117645, 'problem': 0.588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>130</td>\n",
       "      <td>College tuition planning</td>\n",
       "      <td>Find documents discussing the spiraling cost o...</td>\n",
       "      <td>Documents that describe a plan where parents c...</td>\n",
       "      <td>{'colleg': 1, 'tuition': 1, 'plan': 1}</td>\n",
       "      <td>{'colleg': -1.3333333333333333, 'tuition': -1....</td>\n",
       "      <td>{'colleg': -0.33333333333333326, 'tuition': -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>131</td>\n",
       "      <td>television U.S. children</td>\n",
       "      <td>Produce documents reflecting actions taken to ...</td>\n",
       "      <td>Documents discussing actions taken in the U.S....</td>\n",
       "      <td>{'televis': 1, 'children': 1}</td>\n",
       "      <td>{'televis': -13.0, 'children': -2.5}</td>\n",
       "      <td>{'televis': -12.0, 'children': -1.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>132</td>\n",
       "      <td>Friendly fire deaths</td>\n",
       "      <td>Identify any instances where death has resulte...</td>\n",
       "      <td>Relevant documents describe death occurring du...</td>\n",
       "      <td>{'friendli': 1, 'death': 1, 'fire': 1}</td>\n",
       "      <td>{'friendli': 0.2857142857142857, 'death': -3.1...</td>\n",
       "      <td>{'friendli': 1, 'death': -2.142857142857143, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>133</td>\n",
       "      <td>Anti-rejection transplant drugs</td>\n",
       "      <td>Identify immune-suppressing drugs that are use...</td>\n",
       "      <td>Research using human stem cell cultures are ir...</td>\n",
       "      <td>{'drug': 1, 'reject': 1, 'anti': 1, 'transplan...</td>\n",
       "      <td>{'drug': -19.8, 'reject': 1.0, 'anti': -0.8, '...</td>\n",
       "      <td>{'drug': -18.8, 'reject': 2.0, 'anti': 0.19999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>134</td>\n",
       "      <td>Crime Statistics Great Britain</td>\n",
       "      <td>Find all documents relating to the increase or...</td>\n",
       "      <td>Parliamentary debate, political speeches, call...</td>\n",
       "      <td>{'crime': 1, 'statist': 1, 'great': 1, 'britai...</td>\n",
       "      <td>{'crime': -15.6, 'statist': -2.2, 'great': -0....</td>\n",
       "      <td>{'crime': -14.6, 'statist': -1.200000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>135</td>\n",
       "      <td>WTO trade debates</td>\n",
       "      <td>The WTO has had an impact upon world trade. Wh...</td>\n",
       "      <td>Relevant documents will contain information pe...</td>\n",
       "      <td>{'wto': 1, 'trade': 1, 'debat': 1}</td>\n",
       "      <td>{'wto': -1.2857142857142858, 'trade': -5.57142...</td>\n",
       "      <td>{'wto': -0.2857142857142858, 'trade': -4.57142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>136</td>\n",
       "      <td>Substance abuse crime</td>\n",
       "      <td>Find documents linking substance abuse to othe...</td>\n",
       "      <td>Relevant documents directly associated substan...</td>\n",
       "      <td>{'crime': 1, 'abus': 1, 'substanc': 1}</td>\n",
       "      <td>{'crime': -2.375, 'abus': -1.625, 'substanc': ...</td>\n",
       "      <td>{'crime': -1.375, 'abus': -0.625, 'substanc': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>137</td>\n",
       "      <td>Sea turtle deaths</td>\n",
       "      <td>Identify any information relevant to the death...</td>\n",
       "      <td>Relevant documents will provide any informatio...</td>\n",
       "      <td>{'turtl': 1, 'sea': 1, 'death': 1}</td>\n",
       "      <td>{'turtl': 1.6666666666666667, 'sea': -13.33333...</td>\n",
       "      <td>{'turtl': 2.666666666666667, 'sea': -12.333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>138</td>\n",
       "      <td>Creutzfeldt-Jakob, mad cow disease</td>\n",
       "      <td>Find documents which contain information on ca...</td>\n",
       "      <td>Relevant documents cite specific cases or the ...</td>\n",
       "      <td>{'cow': 1, 'creutzfeldt': 1, 'diseas': 1, 'jak...</td>\n",
       "      <td>{'cow': -42.57142857142857, 'creutzfeldt': -5....</td>\n",
       "      <td>{'cow': -41.57142857142857, 'creutzfeldt': -4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>139</td>\n",
       "      <td>Pig organ transplants</td>\n",
       "      <td>Research reports on the use of pigs for organ ...</td>\n",
       "      <td>Relevant documents show the development of pig...</td>\n",
       "      <td>{'pig': 1, 'organ': 1, 'transplant': 1}</td>\n",
       "      <td>{'pig': -3.3333333333333335, 'organ': -1.33333...</td>\n",
       "      <td>{'pig': -2.3333333333333335, 'organ': -0.33333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>140</td>\n",
       "      <td>computer simulation</td>\n",
       "      <td>Reports on how computer simulation and modelin...</td>\n",
       "      <td>Documents reporting the use of simulation and ...</td>\n",
       "      <td>{'simul': 1, 'comput': 1}</td>\n",
       "      <td>{'simul': 1.2727272727272727, 'comput': -13.72...</td>\n",
       "      <td>{'simul': 2.2727272727272725, 'comput': -12.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>141</td>\n",
       "      <td>Environment National Park</td>\n",
       "      <td>Find documents relating to environmental probl...</td>\n",
       "      <td>Documents addressing National Forests problems...</td>\n",
       "      <td>{'nation': 1, 'park': 1, 'environ': 1}</td>\n",
       "      <td>{'nation': 2.5, 'park': 2.125, 'environ': 0.875}</td>\n",
       "      <td>{'nation': 3.5, 'park': 3.125, 'environ': 1.875}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>142</td>\n",
       "      <td>Illiteracy Arab Africa</td>\n",
       "      <td>Research reports on the illiteracy rates in Af...</td>\n",
       "      <td>Relevant documents discuss illiteracy in Afric...</td>\n",
       "      <td>{'arab': 1, 'africa': 1, 'illiteraci': 1}</td>\n",
       "      <td>{'arab': -1.5, 'africa': 0.0, 'illiteraci': -2...</td>\n",
       "      <td>{'arab': -0.5, 'africa': 1.0, 'illiteraci': -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>143</td>\n",
       "      <td>Improving aircraft safety</td>\n",
       "      <td>What is being done by U.S. airplane manufactur...</td>\n",
       "      <td>Relevant documents reflect independent actions...</td>\n",
       "      <td>{'safeti': 1, 'improv': 1, 'aircraft': 1}</td>\n",
       "      <td>{'safeti': -24.5, 'improv': -2.75, 'aircraft':...</td>\n",
       "      <td>{'safeti': -23.5, 'improv': -1.75, 'aircraft':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>144</td>\n",
       "      <td>Mountain climbing deaths</td>\n",
       "      <td>Identify any information where mountain climbi...</td>\n",
       "      <td>Relevant documents identify any instance of de...</td>\n",
       "      <td>{'mountain': 1, 'death': 1, 'climb': 1}</td>\n",
       "      <td>{'mountain': -7.166666666666667, 'death': -4.5...</td>\n",
       "      <td>{'mountain': -6.166666666666667, 'death': -3.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>145</td>\n",
       "      <td>Airline passenger disruptions</td>\n",
       "      <td>Identify any disruptions brought about by unru...</td>\n",
       "      <td>Documents that identify any instance where a d...</td>\n",
       "      <td>{'disrupt': 1, 'airlin': 1, 'passeng': 1}</td>\n",
       "      <td>{'disrupt': -0.4, 'airlin': -64.2, 'passeng': ...</td>\n",
       "      <td>{'disrupt': 0.6, 'airlin': -63.2, 'passeng': -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>146</td>\n",
       "      <td>Germ warfare</td>\n",
       "      <td>Research reports on germ warfare. Including de...</td>\n",
       "      <td>Reports on the use or development of germ or b...</td>\n",
       "      <td>{'germ': 1, 'warfar': 1}</td>\n",
       "      <td>{'germ': -0.7692307692307693, 'warfar': -0.230...</td>\n",
       "      <td>{'germ': 0.23076923076923073, 'warfar': 0.7692...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>147</td>\n",
       "      <td>Natural gas vehicles</td>\n",
       "      <td>What are the pros and cons regarding the use o...</td>\n",
       "      <td>Documents that are indicative of the pro's and...</td>\n",
       "      <td>{'vehicl': 1, 'ga': 1, 'natur': 1}</td>\n",
       "      <td>{'vehicl': -9.333333333333334, 'ga': -80.5, 'n...</td>\n",
       "      <td>{'vehicl': -8.333333333333334, 'ga': -79.5, 'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>148</td>\n",
       "      <td>NAFTA</td>\n",
       "      <td>The NAFTA was created in the 90s. What are the...</td>\n",
       "      <td>Documents containing information about current...</td>\n",
       "      <td>{'nafta': 1}</td>\n",
       "      <td>{'nafta': -3.9166666666666665}</td>\n",
       "      <td>{'nafta': -2.9166666666666665}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>149</td>\n",
       "      <td>Aid to handicapped people</td>\n",
       "      <td>Find documents reflecting actions to aid handi...</td>\n",
       "      <td>Relevant documents clearly demonstrate efforts...</td>\n",
       "      <td>{'aid': 1, 'handicap': 1, 'peopl': 1}</td>\n",
       "      <td>{'aid': -6.0, 'handicap': -1.4, 'peopl': -4.0}</td>\n",
       "      <td>{'aid': -5.0, 'handicap': -0.3999999999999999,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>150</td>\n",
       "      <td>Drive-by shootings</td>\n",
       "      <td>Research documents on drive-by shootings.</td>\n",
       "      <td>Documents indicating shots fired from a passin...</td>\n",
       "      <td>{'shoot': 1, 'drive': 1}</td>\n",
       "      <td>{'shoot': -9.5, 'drive': -1.25}</td>\n",
       "      <td>{'shoot': -8.5, 'drive': -0.25}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number                                   title  \\\n",
       "0     101                      Economic espionage   \n",
       "1     102              Convicts, repeat offenders   \n",
       "2     103                     Ferry Boat sinkings   \n",
       "3     104            Rescue of kidnapped children   \n",
       "4     105             Sport Utility Vehicles U.S.   \n",
       "5     106    Government supported school vouchers   \n",
       "6     107                   Tourism Great Britain   \n",
       "7     108               Harmful weight-loss drugs   \n",
       "8     109                     Child custody cases   \n",
       "9     110           Terrorism Middle East tourism   \n",
       "10    111            Telemarketing practices U.S.   \n",
       "11    112                    School bus accidents   \n",
       "12    113                   Ford foreign ventures   \n",
       "13    114               Effects of global warming   \n",
       "14    115                      Indian casino laws   \n",
       "15    116                 Archaeology discoveries   \n",
       "16    117             Organ transplants in the UK   \n",
       "17    118  Progress in treatment of schizophrenia   \n",
       "18    119                         U.S. gas prices   \n",
       "19    120                 Deaths mining accidents   \n",
       "20    121          China Pakistan nuclear missile   \n",
       "21    122                      Symptoms Parkinson   \n",
       "22    123           Newspaper circulation decline   \n",
       "23    124                        Aborigine health   \n",
       "24    125                   Scottish Independence   \n",
       "25    126                     Nuclear plants U.S.   \n",
       "26    127               U.S. automobile seat belt   \n",
       "27    128                        Child labor laws   \n",
       "28    129            Problems illegal aliens U.S.   \n",
       "29    130                College tuition planning   \n",
       "30    131                television U.S. children   \n",
       "31    132                    Friendly fire deaths   \n",
       "32    133         Anti-rejection transplant drugs   \n",
       "33    134          Crime Statistics Great Britain   \n",
       "34    135                       WTO trade debates   \n",
       "35    136                   Substance abuse crime   \n",
       "36    137                       Sea turtle deaths   \n",
       "37    138      Creutzfeldt-Jakob, mad cow disease   \n",
       "38    139                   Pig organ transplants   \n",
       "39    140                     computer simulation   \n",
       "40    141               Environment National Park   \n",
       "41    142                  Illiteracy Arab Africa   \n",
       "42    143               Improving aircraft safety   \n",
       "43    144                Mountain climbing deaths   \n",
       "44    145           Airline passenger disruptions   \n",
       "45    146                            Germ warfare   \n",
       "46    147                    Natural gas vehicles   \n",
       "47    148                                   NAFTA   \n",
       "48    149               Aid to handicapped people   \n",
       "49    150                      Drive-by shootings   \n",
       "\n",
       "                                          description  \\\n",
       "0   What is being done to counter economic espiona...   \n",
       "1   Search for information pertaining to crimes co...   \n",
       "2   Documents will report on any sinkings of Ferry...   \n",
       "3   Identify a kidnapping of a child or children w...   \n",
       "4   Find documents that will illustrate the phenom...   \n",
       "5   Research documents on the pros/cons of governm...   \n",
       "6   Retrieve documents pertaining to tourism into ...   \n",
       "7   Identify medicines used for obesity or weight-...   \n",
       "8            Research reports on child custody cases.   \n",
       "9   What effect has Middle East terrorism had on t...   \n",
       "10  Find documents which reflect telemarketing pra...   \n",
       "11  Identify any documents noting school bus accid...   \n",
       "12  Track joint ventures, partnerships and coopera...   \n",
       "13  Evidence of effects of global warming or the g...   \n",
       "14  Research the state laws regarding the construc...   \n",
       "15  Find current documents on new archaeological d...   \n",
       "16  Research reports on organ transplantation in t...   \n",
       "17  Provide documents reflecting any progress in m...   \n",
       "18  Find documents discussing possible reasons for...   \n",
       "19  Identify any documents mentioning deaths in mi...   \n",
       "20  Search for evidence of whether or not China is...   \n",
       "21  Find early symptoms of diagnosing Parkinson's ...   \n",
       "22                                               <NA>   \n",
       "23  Research reports on the health of aborigine pe...   \n",
       "24  The Scottish people have been pushing for inde...   \n",
       "25  Find the location and status of United States ...   \n",
       "26  Find documents concerning the use of automobil...   \n",
       "27  Research documents covering the current state ...   \n",
       "28  Find documents referencing problems resulting ...   \n",
       "29  Find documents discussing the spiraling cost o...   \n",
       "30  Produce documents reflecting actions taken to ...   \n",
       "31  Identify any instances where death has resulte...   \n",
       "32  Identify immune-suppressing drugs that are use...   \n",
       "33  Find all documents relating to the increase or...   \n",
       "34  The WTO has had an impact upon world trade. Wh...   \n",
       "35  Find documents linking substance abuse to othe...   \n",
       "36  Identify any information relevant to the death...   \n",
       "37  Find documents which contain information on ca...   \n",
       "38  Research reports on the use of pigs for organ ...   \n",
       "39  Reports on how computer simulation and modelin...   \n",
       "40  Find documents relating to environmental probl...   \n",
       "41  Research reports on the illiteracy rates in Af...   \n",
       "42  What is being done by U.S. airplane manufactur...   \n",
       "43  Identify any information where mountain climbi...   \n",
       "44  Identify any disruptions brought about by unru...   \n",
       "45  Research reports on germ warfare. Including de...   \n",
       "46  What are the pros and cons regarding the use o...   \n",
       "47  The NAFTA was created in the 90s. What are the...   \n",
       "48  Find documents reflecting actions to aid handi...   \n",
       "49          Research documents on drive-by shootings.   \n",
       "\n",
       "                                            narrative  \\\n",
       "0   Documents which identify economic espionage ca...   \n",
       "1   Relevant documents are those which cite actual...   \n",
       "2   Documents that identify any instances where a ...   \n",
       "3   Documents discussing abducted or kidnapped chi...   \n",
       "4   Documents that discuss the growth in ownership...   \n",
       "5   Documents containing statements by elected off...   \n",
       "6   Documents about Scotland, Wales and only North...   \n",
       "7   Relevant documents will show specific, harmful...   \n",
       "8   Relevant documents concentrate on custody case...   \n",
       "9   Relevant documents directly correlate terroris...   \n",
       "10  Telemarketing practices found to be abusive, i...   \n",
       "11  Relevant documents will identify any instances...   \n",
       "12  Current, intact ventures are the only ones rel...   \n",
       "13  Only articles that describe actual changes due...   \n",
       "14  Documents that show laws and ballot initiative...   \n",
       "15  Documents interpreting former discoveries shou...   \n",
       "16  Reports on actual organ transplant cases are r...   \n",
       "17  Documents providing the names of drugs used as...   \n",
       "18  Documents that provide reasons why U.S. gasoli...   \n",
       "19  Documents listing statistics on number of mini...   \n",
       "20  Documents which contain information confirming...   \n",
       "21  Documents discussing people with Parkinsons wi...   \n",
       "22  Documents which cite both circulation decline ...   \n",
       "23  Relevant documents will address current attemp...   \n",
       "24  Documents that only discuss creation of a Scot...   \n",
       "25  Documents giving a specific location of a nucl...   \n",
       "26  Relevant documents show the use of seat belts ...   \n",
       "27  Relevant documents discuss the creation of law...   \n",
       "28  Documents that mention illegal alien activity ...   \n",
       "29  Documents that describe a plan where parents c...   \n",
       "30  Documents discussing actions taken in the U.S....   \n",
       "31  Relevant documents describe death occurring du...   \n",
       "32  Research using human stem cell cultures are ir...   \n",
       "33  Parliamentary debate, political speeches, call...   \n",
       "34  Relevant documents will contain information pe...   \n",
       "35  Relevant documents directly associated substan...   \n",
       "36  Relevant documents will provide any informatio...   \n",
       "37  Relevant documents cite specific cases or the ...   \n",
       "38  Relevant documents show the development of pig...   \n",
       "39  Documents reporting the use of simulation and ...   \n",
       "40  Documents addressing National Forests problems...   \n",
       "41  Relevant documents discuss illiteracy in Afric...   \n",
       "42  Relevant documents reflect independent actions...   \n",
       "43  Relevant documents identify any instance of de...   \n",
       "44  Documents that identify any instance where a d...   \n",
       "45  Reports on the use or development of germ or b...   \n",
       "46  Documents that are indicative of the pro's and...   \n",
       "47  Documents containing information about current...   \n",
       "48  Relevant documents clearly demonstrate efforts...   \n",
       "49  Documents indicating shots fired from a passin...   \n",
       "\n",
       "                                        parsed_titles  \\\n",
       "0                        {'espionag': 1, 'econom': 1}   \n",
       "1            {'offend': 1, 'repeat': 1, 'convict': 1}   \n",
       "2                  {'boat': 1, 'ferri': 1, 'sink': 1}   \n",
       "3            {'kidnap': 1, 'rescu': 1, 'children': 1}   \n",
       "4                {'util': 1, 'sport': 1, 'vehicl': 1}   \n",
       "5   {'support': 1, 'govern': 1, 'school': 1, 'vouc...   \n",
       "6            {'great': 1, 'britain': 1, 'tourism': 1}   \n",
       "7      {'loss': 1, 'harm': 1, 'weight': 1, 'drug': 1}   \n",
       "8               {'case': 1, 'child': 1, 'custodi': 1}   \n",
       "9   {'terror': 1, 'middl': 1, 'east': 1, 'tourism'...   \n",
       "10                    {'telemarket': 1, 'practic': 1}   \n",
       "11                 {'accid': 1, 'school': 1, 'bu': 1}   \n",
       "12             {'ford': 1, 'foreign': 1, 'ventur': 1}   \n",
       "13              {'effect': 1, 'warm': 1, 'global': 1}   \n",
       "14               {'indian': 1, 'casino': 1, 'law': 1}   \n",
       "15                  {'archaeolog': 1, 'discoveri': 1}   \n",
       "16                      {'organ': 1, 'transplant': 1}   \n",
       "17  {'treatment': 1, 'schizophrenia': 1, 'progress...   \n",
       "18                              {'price': 1, 'ga': 1}   \n",
       "19                {'mine': 1, 'accid': 1, 'death': 1}   \n",
       "20  {'nuclear': 1, 'missil': 1, 'china': 1, 'pakis...   \n",
       "21                     {'symptom': 1, 'parkinson': 1}   \n",
       "22           {'newspap': 1, 'declin': 1, 'circul': 1}   \n",
       "23                       {'health': 1, 'aborigin': 1}   \n",
       "24                     {'scottish': 1, 'independ': 1}   \n",
       "25                         {'plant': 1, 'nuclear': 1}   \n",
       "26             {'belt': 1, 'automobil': 1, 'seat': 1}   \n",
       "27                 {'labor': 1, 'child': 1, 'law': 1}   \n",
       "28             {'alien': 1, 'problem': 1, 'illeg': 1}   \n",
       "29             {'colleg': 1, 'tuition': 1, 'plan': 1}   \n",
       "30                      {'televis': 1, 'children': 1}   \n",
       "31             {'friendli': 1, 'death': 1, 'fire': 1}   \n",
       "32  {'drug': 1, 'reject': 1, 'anti': 1, 'transplan...   \n",
       "33  {'crime': 1, 'statist': 1, 'great': 1, 'britai...   \n",
       "34                 {'wto': 1, 'trade': 1, 'debat': 1}   \n",
       "35             {'crime': 1, 'abus': 1, 'substanc': 1}   \n",
       "36                 {'turtl': 1, 'sea': 1, 'death': 1}   \n",
       "37  {'cow': 1, 'creutzfeldt': 1, 'diseas': 1, 'jak...   \n",
       "38            {'pig': 1, 'organ': 1, 'transplant': 1}   \n",
       "39                          {'simul': 1, 'comput': 1}   \n",
       "40             {'nation': 1, 'park': 1, 'environ': 1}   \n",
       "41          {'arab': 1, 'africa': 1, 'illiteraci': 1}   \n",
       "42          {'safeti': 1, 'improv': 1, 'aircraft': 1}   \n",
       "43            {'mountain': 1, 'death': 1, 'climb': 1}   \n",
       "44          {'disrupt': 1, 'airlin': 1, 'passeng': 1}   \n",
       "45                           {'germ': 1, 'warfar': 1}   \n",
       "46                 {'vehicl': 1, 'ga': 1, 'natur': 1}   \n",
       "47                                       {'nafta': 1}   \n",
       "48              {'aid': 1, 'handicap': 1, 'peopl': 1}   \n",
       "49                           {'shoot': 1, 'drive': 1}   \n",
       "\n",
       "                                    specificity_score  \\\n",
       "0   {'espionag': -0.2857142857142857, 'econom': 0....   \n",
       "1   {'offend': 0.2222222222222222, 'repeat': 0.103...   \n",
       "2   {'boat': -3.2857142857142856, 'ferri': -2.8571...   \n",
       "3   {'kidnap': 1.425, 'rescu': 1.0916666666666666,...   \n",
       "4   {'util': 0.8125, 'sport': 2.25, 'vehicl': 3.9375}   \n",
       "5   {'support': -1.25, 'govern': -5.5, 'school': -...   \n",
       "6   {'great': -0.3333333333333333, 'britain': 0.66...   \n",
       "7   {'loss': -12.0, 'harm': -0.6666666666666666, '...   \n",
       "8      {'case': 1.55, 'child': -0.55, 'custodi': 1.5}   \n",
       "9   {'terror': -1.6, 'middl': -18.8, 'east': -37.0...   \n",
       "10  {'telemarket': -2.3333333333333335, 'practic':...   \n",
       "11  {'accid': -4.5, 'school': -0.5, 'bu': -5.16666...   \n",
       "12  {'ford': -15.416666666666666, 'foreign': -0.41...   \n",
       "13     {'effect': -0.2, 'warm': -1.2, 'global': -2.4}   \n",
       "14  {'indian': 0.3333333333333333, 'casino': -35.6...   \n",
       "15        {'archaeolog': -0.375, 'discoveri': -4.125}   \n",
       "16  {'organ': -4.666666666666667, 'transplant': -1...   \n",
       "17  {'treatment': -8.666666666666666, 'schizophren...   \n",
       "18                      {'price': -65.75, 'ga': -3.5}   \n",
       "19  {'mine': -30.11111111111111, 'accid': -0.22222...   \n",
       "20  {'nuclear': -13.142857142857142, 'missil': -2....   \n",
       "21  {'symptom': -0.5333333333333333, 'parkinson': ...   \n",
       "22  {'newspap': -48.666666666666664, 'declin': -4....   \n",
       "23  {'health': -4.166666666666667, 'aborigin': -8....   \n",
       "24                {'scottish': 0.5, 'independ': 1.75}   \n",
       "25  {'plant': -0.7368421052631579, 'nuclear': -0.5...   \n",
       "26     {'belt': -0.2, 'automobil': 0.2, 'seat': -4.8}   \n",
       "27   {'labor': -11.75, 'child': -41.0, 'law': -19.25}   \n",
       "28  {'alien': 1.0588235294117647, 'problem': -0.41...   \n",
       "29  {'colleg': -1.3333333333333333, 'tuition': -1....   \n",
       "30               {'televis': -13.0, 'children': -2.5}   \n",
       "31  {'friendli': 0.2857142857142857, 'death': -3.1...   \n",
       "32  {'drug': -19.8, 'reject': 1.0, 'anti': -0.8, '...   \n",
       "33  {'crime': -15.6, 'statist': -2.2, 'great': -0....   \n",
       "34  {'wto': -1.2857142857142858, 'trade': -5.57142...   \n",
       "35  {'crime': -2.375, 'abus': -1.625, 'substanc': ...   \n",
       "36  {'turtl': 1.6666666666666667, 'sea': -13.33333...   \n",
       "37  {'cow': -42.57142857142857, 'creutzfeldt': -5....   \n",
       "38  {'pig': -3.3333333333333335, 'organ': -1.33333...   \n",
       "39  {'simul': 1.2727272727272727, 'comput': -13.72...   \n",
       "40   {'nation': 2.5, 'park': 2.125, 'environ': 0.875}   \n",
       "41  {'arab': -1.5, 'africa': 0.0, 'illiteraci': -2...   \n",
       "42  {'safeti': -24.5, 'improv': -2.75, 'aircraft':...   \n",
       "43  {'mountain': -7.166666666666667, 'death': -4.5...   \n",
       "44  {'disrupt': -0.4, 'airlin': -64.2, 'passeng': ...   \n",
       "45  {'germ': -0.7692307692307693, 'warfar': -0.230...   \n",
       "46  {'vehicl': -9.333333333333334, 'ga': -80.5, 'n...   \n",
       "47                     {'nafta': -3.9166666666666665}   \n",
       "48     {'aid': -6.0, 'handicap': -1.4, 'peopl': -4.0}   \n",
       "49                    {'shoot': -9.5, 'drive': -1.25}   \n",
       "\n",
       "                                       weighted_terms  \n",
       "0   {'espionag': 0.7142857142857143, 'econom': 1.5...  \n",
       "1          {'offend': 1, 'repeat': 1, 'convict': 2.0}  \n",
       "2   {'boat': -2.2857142857142856, 'ferri': -1.8571...  \n",
       "3   {'kidnap': 2.425, 'rescu': 2.091666666666667, ...  \n",
       "4   {'util': 1.8125, 'sport': 3.25, 'vehicl': 4.9375}  \n",
       "5   {'support': -0.25, 'govern': -4.5, 'school': -...  \n",
       "6   {'great': 0.6666666666666667, 'britain': 1.666...  \n",
       "7   {'loss': -11.0, 'harm': 0.33333333333333337, '...  \n",
       "8   {'case': 2.55, 'child': 0.44999999999999996, '...  \n",
       "9   {'terror': -0.6000000000000001, 'middl': -17.8...  \n",
       "10  {'telemarket': -1.3333333333333335, 'practic':...  \n",
       "11  {'accid': -3.5, 'school': 0.5, 'bu': -4.166666...  \n",
       "12  {'ford': -14.416666666666666, 'foreign': 0.583...  \n",
       "13  {'effect': 0.8, 'warm': -0.19999999999999996, ...  \n",
       "14  {'indian': 1, 'casino': -34.666666666666664, '...  \n",
       "15         {'archaeolog': 0.625, 'discoveri': -3.125}  \n",
       "16  {'organ': -3.666666666666667, 'transplant': -1...  \n",
       "17  {'treatment': -7.666666666666666, 'schizophren...  \n",
       "18                      {'price': -64.75, 'ga': -2.5}  \n",
       "19  {'mine': -29.11111111111111, 'accid': 0.777777...  \n",
       "20  {'nuclear': -12.142857142857142, 'missil': -1....  \n",
       "21  {'symptom': 0.4666666666666667, 'parkinson': 3...  \n",
       "22  {'newspap': -47.666666666666664, 'declin': -3....  \n",
       "23  {'health': -3.166666666666667, 'aborigin': -7....  \n",
       "24                {'scottish': 1.5, 'independ': 2.75}  \n",
       "25  {'plant': 0.26315789473684215, 'nuclear': 0.47...  \n",
       "26        {'belt': 0.8, 'automobil': 1, 'seat': -3.8}  \n",
       "27   {'labor': -10.75, 'child': -40.0, 'law': -18.25}  \n",
       "28  {'alien': 2.0588235294117645, 'problem': 0.588...  \n",
       "29  {'colleg': -0.33333333333333326, 'tuition': -0...  \n",
       "30               {'televis': -12.0, 'children': -1.5}  \n",
       "31  {'friendli': 1, 'death': -2.142857142857143, '...  \n",
       "32  {'drug': -18.8, 'reject': 2.0, 'anti': 0.19999...  \n",
       "33  {'crime': -14.6, 'statist': -1.200000000000000...  \n",
       "34  {'wto': -0.2857142857142858, 'trade': -4.57142...  \n",
       "35  {'crime': -1.375, 'abus': -0.625, 'substanc': ...  \n",
       "36  {'turtl': 2.666666666666667, 'sea': -12.333333...  \n",
       "37  {'cow': -41.57142857142857, 'creutzfeldt': -4....  \n",
       "38  {'pig': -2.3333333333333335, 'organ': -0.33333...  \n",
       "39  {'simul': 2.2727272727272725, 'comput': -12.72...  \n",
       "40   {'nation': 3.5, 'park': 3.125, 'environ': 1.875}  \n",
       "41  {'arab': -0.5, 'africa': 1.0, 'illiteraci': -1...  \n",
       "42  {'safeti': -23.5, 'improv': -1.75, 'aircraft':...  \n",
       "43  {'mountain': -6.166666666666667, 'death': -3.5...  \n",
       "44  {'disrupt': 0.6, 'airlin': -63.2, 'passeng': -...  \n",
       "45  {'germ': 0.23076923076923073, 'warfar': 0.7692...  \n",
       "46  {'vehicl': -8.333333333333334, 'ga': -79.5, 'n...  \n",
       "47                     {'nafta': -2.9166666666666665}  \n",
       "48  {'aid': -5.0, 'handicap': -0.3999999999999999,...  \n",
       "49                    {'shoot': -8.5, 'drive': -0.25}  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_frame\n",
    "#{'espionag': -0.2857142857142857, 'econom': 0...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25_results = {}\n",
    "\n",
    "for query_key, collection in document_set.items():\n",
    "    query = query_frame.loc[query_frame['Number'] == query_key, 'parsed_titles'].iloc[0]\n",
    "    BM25_results[query_key] = BM25(collection, query)\n",
    "    write_scores_to_file(BM25_results[query_key], f\"BM25_R{query_key}Ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Jelinek-Mercer Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** Design a Jelinek-Mercer based Language Model (**JM_LM**) that ranks documents in each data collection using the corresponding topic (query) for all 50 data collections.\n",
    "\n",
    "\n",
    "**Inputs:** 50 long queries (topics) in *the50Queries.txt* and the corresponding 50 data collections (*Data_C101, Data_C102, …, Data_C150*).\n",
    "\n",
    "\n",
    "**Output:** 50 ranked document files (e.g., for Query *R107*, the output file name is “JM_LM_R107Ranking.dat”) for all 50 data collections and save them in the folder RankingOutputs”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each long query (topic) $R_x$, you need to use the following equation to calculate a conditional probability for each document $D$ in the corresponding data collection (dataset):\n",
    "\n",
    "\n",
    "$p(R_x|D)=\\Pi_{i=1}^n ((1-\\lambda)\\cdot\\frac{f_{q_i,D}}{|D|}+\\lambda\\cdot\\frac{c_{q_i}}{|C|})$\n",
    "\n",
    "- $f_{q_i,D}$ is the number of times query word $q_i$ occurs in document $D$\n",
    "- $|D|$ is the number of word occurrences in $D$\n",
    "- $c_{q_i}$ is the number of times query word $q_i$ occurs in the data collection $C$\n",
    "- $|C|$ is the total number of word occurrences in data collection $C$\n",
    "- `λ = 0.4`\n",
    "\n",
    "**Formally describe your design for JM_LM** in an algorithm to **rank documents in each data collection *using corresponding query* (topic) ***for all 50 data collections*****. When you use the probabilities to rank the documents of each data collection, you also need to **answer what the query feature function and document feature function are**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JM_LM(collection, query):\n",
    "    \"\"\"\n",
    "    Calculate the conditional probability of each document given a query using the Jelinek-Mercer smoothing Language Model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Type check to ensure collection is an bow_document_collection object\n",
    "    if not isinstance(collection, bow_document_collection):\n",
    "        raise TypeError(\"collection: must be a bow_document_collection object.\")\n",
    "    \n",
    "    # Check if the collection contains any documents\n",
    "    if len(collection.docs) == 0:\n",
    "        raise AttributeError(\"bow_document_collection: object contains no documents (Rcv1Doc objects).\")\n",
    "    \n",
    "    # Validate that the query is a dictionary\n",
    "    if not isinstance(query, dict):\n",
    "        raise TypeError(\"query: must be a dict object.\")\n",
    "    \n",
    "    # Set lambda parameter for Jelinek-Mercer smoothing\n",
    "    lambda_val = 0.4\n",
    "    \n",
    "    # Calculate the total length of the corpus by summing the lengths of all documents\n",
    "    total_corpus_length = sum(doc.doc_len for doc in collection.docs.values())\n",
    "    \n",
    "    # Initialize an empty dictionary to store the scores for each document\n",
    "    doc_scores = {}\n",
    "\n",
    "    # Iterate through each term in the query\n",
    "    for query_term in query:\n",
    "        # Get the frequency of the query term in the entire collection\n",
    "        c_qi = collection.term_doc_count.get(query_term, 0)\n",
    "        \n",
    "        # Iterate through each document in the collection\n",
    "        for doc_id, doc in collection.docs.items():\n",
    "            # Get the frequency of the query term in the current document\n",
    "            f_qi_D = doc.terms.get(query_term, 0)\n",
    "\n",
    "            # Calculate the probability of the term occurring in the document\n",
    "            p_doc = (f_qi_D / doc.doc_len) if doc.doc_len > 0 else 0\n",
    "            \n",
    "            # Calculate the probability of the term occurring in the whole collection\n",
    "            p_coll = (c_qi / total_corpus_length) if total_corpus_length > 0 else 0\n",
    "\n",
    "            # Calculate the smoothed score for the term using Jelinek-Mercer smoothing\n",
    "            score = (1 - lambda_val) * p_doc + lambda_val * p_coll\n",
    "\n",
    "            # Initialize the score for the document if not already done\n",
    "            if doc_id not in doc_scores:\n",
    "                doc_scores[doc_id] = 1  # Multiplicative identity\n",
    "\n",
    "            # Multiply the score to the cumulative product if it's greater than zero\n",
    "            if score > 0:\n",
    "                doc_scores[doc_id] *= score\n",
    "\n",
    "    # Sort the documents by their score in descending order and return the sorted dictionary\n",
    "    doc_scores = dict(sorted(doc_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Return the document scores\n",
    "    return doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JM_LM_results = {}\n",
    "\n",
    "for query_key, collection in document_set.items():\n",
    "    query = query_frame.loc[query_frame['Number'] == query_key, 'parsed_titles'].iloc[0]\n",
    "    JM_LM_results[query_key] = JM_LM(collection, query)\n",
    "    write_scores_to_file(JM_LM_results[query_key], f\"JM_LM_R{query_key}Ranking\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Pseudo-Relevance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** Based on the knowledge you gained from this unit, design a pseudo-relevance model (My_PRM) to rank documents in each data collection using the corresponding topic (query) for all 50 data collections.\n",
    "\n",
    "\n",
    "**Inputs:** 50 long queries (topics) in the50Queries.txt and the corresponding 50 data collections (Data_C101, Data_C102, …, Data_C150).\n",
    "\n",
    "\n",
    "**Output:** 50 ranked document files (e.g., for Query R107, the output file name is “My_PRM_R107Ranking.dat”) for all 50 data collections and save them in the folder RankingOutputs”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formally describe your design for My_PRM** in an algorithm to **rank documents in each data collection *using corresponding query* (topic) ***for all 50 data collections*****.Your *approach should be generic*; that means it is feasible to be used for other topics (queries). You also need to **discuss the differences between My_PRM and the other two models (BM25 and JM_LM)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1: list, vector2: list) -> float:\n",
    "    \"\"\"\n",
    "    This function calculates the cosine similarity for two vectors. \n",
    "    It returns a float value that represents the similarity. \n",
    "    \"\"\"\n",
    "    dot_product = sum(x * y for x, y in zip(vector1, vector2)) # Element-wise multiplication\n",
    "    norm1 = math.sqrt(sum(x ** 2 for x in vector1)) # Calculates the euclidean distance\n",
    "    norm2 = math.sqrt(sum(x ** 2 for x in vector2))\n",
    "\n",
    "    # Return cosine similarity if euclidean distance is not zero, otherwise the similarity is zero\n",
    "    return dot_product / (norm1 * norm2) if ((norm1 and norm2) != 0) else 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vector_Space_Model(collection: Rcv1Coll, query: dict) -> dict:\n",
    "    \"\"\"\n",
    "    The Vector Space Model is an algorithm that calculates scores for each document\n",
    "    based on a given query. The model incorporates certain dimensions that can be\n",
    "    changed appropriately, such as similiarity measures, query and the equation for \n",
    "    calculating document weights. The following function uses the cosine similarity \n",
    "    and the tf-idf equation. It returns a dictionary that contains documents and \n",
    "    scores respectively.\n",
    "    https://www.sciencedirect.com/topics/computer-science/vector-space-models#:~:text=The%20Vector%20Space%20Model%20is,vectors%20into%20a%20numerical%20format.\n",
    "    \"\"\"\n",
    "    # Type check to ensure coll is a Rcv1Coll\n",
    "    if not isinstance(collection, Rcv1Coll):\n",
    "        raise TypeError(\"collection: must be a Rcv1Coll object.\")\n",
    "    \n",
    "    # If no collection contains no documents, raise attribute error\n",
    "    if len(collection.docs) == 0:\n",
    "        raise AttributeError(\"Rcv1collection: object contains no documents (Rcv1Doc objects).\")\n",
    "    \n",
    "    # Type check to ensure query is a dict\n",
    "    if not isinstance(query, dict):\n",
    "        raise TypeError(\"query: must be a dict object.\")\n",
    "    \n",
    "    # Initializations\n",
    "    document_similarity_scores = {} \n",
    "    document_vectors = {}\n",
    "    documents_term_frequency = {}\n",
    "    idf_component = {}\n",
    "    N = len(collection.docs)  # total number of documents in the collection\n",
    "\n",
    "    # Constructs a dict with all terms in the collection: \n",
    "    # Term is the key - amount of occurrences of term in all documents is the corresponding value\n",
    "    for doc_ID, doc in collection.docs.items():\n",
    "        for term, frequency in doc.get_term_list().items():\n",
    "            documents_term_frequency[term] = documents_term_frequency.get(term, 0) + 1\n",
    "\n",
    "    # Calculate idf for all terms \n",
    "    for term, doc_freq in documents_term_frequency.items():\n",
    "        idf_component[term] = math.log(N / doc_freq, 10)\n",
    "\n",
    "    # Get all terms of the collection\n",
    "    all_terms = set(documents_term_frequency.keys())\n",
    "\n",
    "    # Represents a general n-dimensional vector, which will be used to construct \n",
    "    # the query- and document-vector. Therefore, a normalization is not necessary, \n",
    "    # due to the fact that the algorithm doesn't compare documents and different queries against each other.\n",
    "    vector = [0] * len(all_terms)\n",
    "    query_vector = [0] * len(all_terms)\n",
    "\n",
    "    # Convert the query parameter into a vector representation\n",
    "    for index, term in enumerate(all_terms):\n",
    "        query_vector[index] = query.get(term, 0)\n",
    "    \n",
    "    # Calculate weights for each document\n",
    "    for doc_ID, doc in collection.docs.items():\n",
    "        term_freq_dict = doc.get_term_list()\n",
    "        # Loop through all terms \n",
    "        for index, term in enumerate(all_terms):\n",
    "            # Calculate the term weigths using tf-idf equation\n",
    "            vector[index] = term_freq_dict.get(term, 0) * idf_component.get(term, 0)\n",
    "        # Store weighted vector for every document\n",
    "        document_vectors[doc_ID] = vector \n",
    "\n",
    "    # Calculate cosine similarity for query and documents\n",
    "    for doc_ID, doc_vector in document_vectors.items():\n",
    "        document_similarity_scores[doc_ID] = cosine_similarity(doc_vector, query_vector)\n",
    "\n",
    "    # Return documents in descending order (based on values of the weights)\n",
    "    return dict(sorted(document_similarity_scores.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w5(collection: Rcv1Coll, marked_documents, theta) -> dict:\n",
    "    \"\"\"\n",
    "    This function calculates the weight-5 score for the whole collection based \n",
    "    on a dictionary that contains relevant and irrelevant documents. Theta is \n",
    "    a parameter which can be changed due to receive reasonable results.\n",
    "    This function returns a dictionary with features and their calculated \n",
    "    weights.  \n",
    "    \"\"\"\n",
    "    # Type check to ensure coll is a Rcv1Coll\n",
    "    if not isinstance(collection, Rcv1Coll):\n",
    "        raise TypeError(\"collection: must be a Rcv1Coll object.\")\n",
    "    \n",
    "    # If no collection contains no documents, raise attribute error\n",
    "    if len(collection.docs) == 0:\n",
    "        raise AttributeError(\"Rcv1collection: object contains no documents (Rcv1Doc objects).\")\n",
    "    \n",
    "    # Type check to ensure query is a dict\n",
    "    if not isinstance(query, dict):\n",
    "        raise TypeError(\"query: must be a dict object.\")\n",
    "    \n",
    "    # Initializations\n",
    "    T = {}\n",
    "    ntk = {}\n",
    "    R = 0\n",
    "    N = len(collection.docs)  # total number of documents in the collection\n",
    "    meanW5 = 0\n",
    "    \n",
    "    # Select T from positive documents and r(tk) + n(tk) + R\n",
    "    for doc_id, doc in collection.docs.items():\n",
    "        for term, frequency in doc.get_term_list().items():\n",
    "            if marked_documents[doc_id] == 1:\n",
    "                T[term] = T.get(term, 0) + 1\n",
    "            ntk[term] = ntk.get(term, 0) + 1\n",
    "\n",
    "    # Calculates the amount of relevent documents\n",
    "    for id, marker in  marked_documents.items():\n",
    "        if marker == 1:\n",
    "            R += marker    \n",
    "\n",
    "    # Calculates the w5-score for each term \n",
    "    for term, rtk in T.items():\n",
    "        T[term] = ((rtk + 0.5) / (R-rtk + 0.5)) / ((ntk[term]-rtk+0.5) / (N-ntk[term]-R+rtk+0.5))\n",
    "    \n",
    "    # Calculates the mean of all w5-scores\n",
    "    # If there exist no relevant documents, the mean is zero, due to the fact\n",
    "    # that it is not possible to calculate the division by zero.  \n",
    "    if R == 0:\n",
    "        meanW5 = 0\n",
    "    else: \n",
    "        for term, rtk in T.items():\n",
    "            meanW5 = rtk\n",
    "        meanW5 = meanW5/len(T)\n",
    "    \n",
    "    # Feature selection based on the mean weight5-score and the parameter theta\n",
    "    Features = {t:r for t,r in T.items() if r > meanW5 + theta}\n",
    "\n",
    "    return Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_PRM(weighting_function, collection: Rcv1Coll, query: dict, threshold: int, theta: int) -> dict:\n",
    "    \"\"\"\n",
    "    This function represents a Pseudo-Relevance-Model (PRM) to rank documents \n",
    "    based on pseudo feedback. It accepts a weighting function as parameter such\n",
    "    as the BM25- and Vector Space Model-algorithm to calculate weights for \n",
    "    each document in a given collection with respect to a given query. The \n",
    "    parameters threshold and theta to fine-tune the algorithm. The PRM returns\n",
    "    a sorted dictionary.\n",
    "    \"\"\"\n",
    "    # Ensure that the weighting function is callable\n",
    "    if not callable(weighting_function):\n",
    "        raise TypeError(\"weighting_function must be a callable function.\")\n",
    "    \n",
    "    # Initializations\n",
    "    marked_documents = {}\n",
    "    documents_scores = {}\n",
    "\n",
    "    # 1) Based on the given query, PRM calculates bm25-score/VSM-score for each document\n",
    "    weighting_result = weighting_function(collection, query)\n",
    "\n",
    "    # 2) Based on a defined threshold (e.g. value=1.0), the algorithm marks relevant documents \n",
    "    # (positive label 1) that are greater than the defined threshold, otherwise as irrelevant (negative label 0 )\n",
    "    for doc, score in weighting_result.items():\n",
    "        marked_documents[doc] = 1 if score > threshold else 0\n",
    "\n",
    "    # 3) Calculates w5-score to identify a set of features \n",
    "    w5_results = w5(collection=collection, marked_documents=marked_documents, theta=theta)\n",
    "\n",
    "    # 4) Calculate document scores based on the identified features\n",
    "    for doc_ID, doc in collection.docs.items():\n",
    "        documents_scores[doc_ID] = 0\n",
    "        for term, frequency in doc.get_term_list().items():\n",
    "            documents_scores[doc_ID] += frequency * w5_results.get(term, 0)\n",
    "        \n",
    "    # Return documents in descending order\n",
    "    return dict(sorted(documents_scores.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My_PRM_results = {}\n",
    "\n",
    "for query_key, col in document_set.items():\n",
    "    query_param = query_frame.loc[query_frame['Number'] == query_key, 'parsed_titles'].iloc[0]\n",
    "    My_PRM_results[query_key] = My_PRM(weighting_function=BM25, collection=col, query=query_param, threshold=0.7, theta=0)\n",
    "    # My_PRM_results[query_key] = My_PRM(weighting_function=Vector_Space_Model, collection=col, query=query_param, threshold=0, theta=0)\n",
    "    write_scores_to_file(My_PRM_results[query_key], f\"My_PRM{query_key}Ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** Use Python to implement three models: `BM25`, `JM_LM`, and `My_PRM`, and **test them on the given 50 data collections for the corresponding 50 queries (topics)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Python programs to implement these three models. You can use a .py file (or a .ipynb file) for each model.\n",
    "\n",
    "\n",
    "For each long query, your python programs will produce ranked results and save them into .dat files. For example, for query R107, you can save the ranked results of three models into “BM25_R107Ranking.dat”, “JM_LM_R107Ranking.dat”, and “My_PRM_R107Ranking.dat”, respectively by using the following format:\n",
    "- The first column is the document id (the itemid in the corresponding XML document)\n",
    "- The second column is the document score (or probability).\n",
    "\n",
    "**Describe:** \n",
    "- Python packages or modules (or any open-source software) you used\n",
    "- The data structures used to represent a single document and a set of documents for each model (you can use different data structures for different models).\n",
    "\n",
    "\n",
    "You also need to **test the three models on the given 50 data collections for the 50 queries (topics) by *printing out the top 15 documents* for each data collection (in descending order)**. The **output will also be put in the appendix of your final report**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** Use three effectiveness measures to evaluate the three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you need to **use the relevance judgments (EvaluationBenchmark.zip)** to **compare with the ranking outputs in the folder of “RankingOutputs” for the selected effectiveness metric** for the three models.\n",
    "\n",
    "\n",
    "You need to use the following three different effectiveness measures to evaluate the document ranking results you saved in the folder “RankingOutputs”:\n",
    "1) Average precision (and MAP)\n",
    "2) Precision@10 (and their average)\n",
    "3) Discounted cumulative gain at rank position 10 ($p = 10$), $DCG_{10}$ (and their average):  \n",
    "    $DCG_p=rel_i+\\sum_{i=2}^p\\frac{rel_i}{log_2(i)}$  \n",
    "        $rel_i=1$ if the document at position $i$ is releveant; otherwise, it is 0.\n",
    "\n",
    "Evaluation results can be summarized in tables or graphs. Examples are provided in the sepcification sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** Recommend a model based on significance test and your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to conduct a significance test to compare models. You can choose a t-test to perform a significance test on the evaluation results (e.g., in Tables 1, 2 and 3). \n",
    "\n",
    "You can compare models between:\n",
    "- **BM25** and **JM_LM**\n",
    "- **BM25** and **My_PRM**\n",
    "- **JM_LM** and **My_PRM**\n",
    "\n",
    "Based on $t$-test results ($p$-value and $t$-statistic), you can recommend a model (You ***want the proposed \"My_RPM\" to be the best because it is your own model***). You can perform the $t$-test using a single effectiveness measure or multiple measures. Generally, using more effectiveness measures provides stronger evidence against the null hypothesis. Note that if the $t$-test is unsatisfactory, you can use the evaluation results to refine **My_PRM** mode. For example, you can adjust parameter settings or update your design and implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
